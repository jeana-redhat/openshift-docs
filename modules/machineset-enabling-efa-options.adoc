// Module included in the following assemblies:
//
// * machine_management/creating_machinesets/creating-machineset-aws.adoc

:_content-type: PROCEDURE
[id="machineset-enabling-efa-options_{context}"]
= Enabling MPI workloads that use an AWS Elastic Fabric Adapter

After configuring a machine set to support the use of an AWS Elastic Fabric Adapter (EFA), you must install additional software to run MPI workloads. 

For more information about using Kubeflow and the MPI Operator in {product-title} and an example, see link:https://cloud.redhat.com/blog/how-to-use-kubeflow-and-the-mpi-operator-on-openshift[How to use Kubeflow and the MPI Operator on OpenShift].

.Prerequisites

* You have configured a machine set to support the use of an EFA.

.Procedure

. Create a machine configuration that allows for an unlimited `memlock`.

.. Generate a base64-encoded string for a file that removes `memlock` limits.
+
.Example raw data
[source,terminal]
----
[crio.runtime]
default_ulimits = [
        "memlock=-1:-1"
]
----
+
.Example base64-encoded data
[source,terminal]
----
W2NyaW8ucnVudGltZV0KZGVmYXVsdF91bGltaXRzID0gWwogICAgICAgICJtZW1sb2NrPS0xOi0xIgpdCg==
----

.. Create a file named `unlimited-memlock.yaml` with the following YAML definition:
+
[source,yaml]
----
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  labels:
    machineconfiguration.openshift.io/role: worker
  name: 02-worker-container-runtime <1>
spec:
  config:
    ignition:
      version: 3.2.0
    storage:
      files:
      - contents:
          source: data:text/plain;charset=utf-8;base64,<base64-encoded-memlock-data> <2>
        mode: 420
        overwrite: true
        path: /etc/crio/crio.conf.d/10-memlock <3>
----
<1> Specify a name for the machine configuration.
<2> Specify a base64-encoded string for the unlimited `memlock` file data.
<3> Specify the path for the `memlock` resource.

.. To create the `MachineConfig` object, enter the following command:
+
[source,terminal]
----
$ oc create -f unlimited-memlock.yaml
----

. Install link:https://github.com/aws/libfabric[libfabric] on your cluster.
+
.Verification
+
Verify that the libfabric DaemonSet that exposes EFA capabilities is running by entering the following command and observing the output:
+
[source,terminal]
----
$ oc get po -n kube-system
----
+
.Example output
+
[source,terminal]
----
NAME                                        READY   STATUS    RESTARTS   AGE
aws-efa-k8s-device-plugin-daemonset-zz5p9   1/1     Running   0          8h
----

. Configure huge pages with a minimum size of 2MB to support the MPI Operator.
+
For more information, see "Configuring huge pages" in the "Node tasks" section of the "Post-installation configuration" documentation.
+
[NOTE]
====
The 2MB minimum required huge page size to support the MPI Operator might not be enough for the size of the instance types within your cluster. Ensure that your huge page configuration meets your requirements.
====

. Install the Kubeflow MPI Operator on your cluster.
+
For more information, see link:https://cloud.redhat.com/blog/how-to-use-kubeflow-and-the-mpi-operator-on-openshift[How to use Kubeflow and the MPI Operator on OpenShift].

. Install the Node Feature Discovery Operator from the OperatorHub on your cluster.
+
For more information, see "Installing the Node Feature Discovery Operator" in the "Node Feature Discovery Operator" section of the "Specialized hardware and driver enablement" documentation.

.Verification

* Verify that the Node Feature Discovery Operator has configured the node status to show the EFA interface as an allocatable resource.